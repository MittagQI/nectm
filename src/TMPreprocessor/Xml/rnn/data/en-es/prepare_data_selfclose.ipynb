{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "created by Liangyou Li @ 25 July 2016\n",
    "'''\n",
    "\n",
    "import sys\n",
    "\n",
    "filepath = 'selfclose.bio.unique'\n",
    "valid_num = 200\n",
    "test_num = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{'ADV': 10, 'NOUN': 3, 'ADP': 7, 'PRON': 11, 'DET': 8, '.': 1, 'PRT': 9, 'NUM': 0, 'X': 6, 'CONJ': 4, 'ADJ': 2, 'VERB': 5}\n",
      "3\n",
      "{'B-T': 1, 'O': 0, 'I-T': 2}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "create dictionaries to map each word and label to a unique int\n",
    "'''\n",
    "\n",
    "words2idx = {}\n",
    "labels2idx = {}\n",
    "with open(filepath,'r') as f:\n",
    "    for line in f:\n",
    "        source, target = line.split(' ||| ')\n",
    "        for wordlabel in source.split() + target.split():\n",
    "            word, label = wordlabel.split('/')\n",
    "            if not word in words2idx:\n",
    "                words2idx[word] = len(words2idx)\n",
    "            if not label in labels2idx:\n",
    "                labels2idx[label] = len(labels2idx)\n",
    "print len(words2idx)\n",
    "print words2idx\n",
    "print len(labels2idx)\n",
    "print labels2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1642 1642 1642 1642\n",
      "[1, 3, 3, 3, 1, 3, 5]\n",
      "[0, 0, 0, 0, 1, 2, 0]\n",
      "[1, 3, 3, 3, 4, 1, 0, 1, 6, 6, 3, 1, 3, 3]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "conver words and labels into numbers\n",
    "neural netword only accept numbers\n",
    "'''\n",
    "\n",
    "source_word = []\n",
    "source_label = []\n",
    "target_word = []\n",
    "target_label = []\n",
    "\n",
    "with open(filepath,'r') as f:\n",
    "    for line in f:\n",
    "        source, target = line.split(' ||| ')\n",
    "        source_wl = source.split()\n",
    "        target_wl = target.split()\n",
    "        \n",
    "        sw = []\n",
    "        sl = []\n",
    "        for wl in source_wl:\n",
    "            w, l = wl.split('/')\n",
    "            sw.append(words2idx[w])\n",
    "            sl.append(labels2idx[l])\n",
    "        source_word.append(sw)\n",
    "        source_label.append(sl)\n",
    "        \n",
    "        tw = []\n",
    "        tl = []\n",
    "        for wl in target_wl:\n",
    "            w, l = wl.split('/')\n",
    "            tw.append(words2idx[w])\n",
    "            tl.append(labels2idx[l])\n",
    "        target_word.append(tw)\n",
    "        target_label.append(tl)\n",
    "print len(source_word), len(source_label), len(target_word), len(target_label)\n",
    "print source_word[5]\n",
    "print source_label[5]\n",
    "print target_word[5]\n",
    "print target_label[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "split data into train, valid and test\n",
    "'''\n",
    "\n",
    "def split_data(dataset):\n",
    "    test = dataset[:200]\n",
    "    valid = dataset[200:400]\n",
    "    train = dataset[400:]\n",
    "    return train, valid, test\n",
    "\n",
    "dic = {'labels2idx' : labels2idx, 'words2idx' : words2idx}\n",
    "\n",
    "train_lex, valid_lex, test_lex = split_data(target_word)\n",
    "train_y, valid_y, test_y = split_data(target_label)\n",
    "train_slex, valid_slex, test_slex = split_data(source_word)\n",
    "train_sy, valid_sy, test_sy = split_data(source_label)\n",
    "\n",
    "train_set = (train_lex, train_y, train_slex, train_sy)\n",
    "valid_set = (valid_lex, valid_y, valid_slex, valid_sy)\n",
    "test_set = (test_lex, test_y, test_slex, test_sy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "save data\n",
    "'''\n",
    "\n",
    "import cPickle\n",
    "corpus = (train_set, valid_set, test_set, dic)\n",
    "cPickle.dump(corpus, open('selfclose.bio.pkl','wb'), protocol=cPickle.HIGHEST_PROTOCOL)\n",
    "#cPickle.dump(dic, open('dic.bio.pkl','wb'), protocol=cPickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
